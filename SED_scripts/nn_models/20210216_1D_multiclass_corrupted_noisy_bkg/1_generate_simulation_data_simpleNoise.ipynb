{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create simualted datasets\n",
    "\n",
    "For both the training and testing datasets.\n",
    "\n",
    "The processing steps include:\n",
    "- Domain randomisation (relrod, spot_spread)\n",
    "- Multiple phases (6)\n",
    "- Corruption of data (disabled for this example)\n",
    "- Adding nose (S&P)\n",
    "- Adding background intensity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.api:The ipywidgets GUI elements are not available, probably because the hyperspy_gui_ipywidgets package is not installed.\n",
      "WARNING:hyperspy.api:The traitsui GUI elements are not available, probably because the hyperspy_gui_traitsui package is not installed.\n",
      "WARNING:silx.opencl.common:Unable to import pyOpenCl. Please install it from: http://pypi.python.org/pypi/pyopencl\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import diffpy.structure\n",
    "from matplotlib import pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "from diffsims.libraries.structure_library import StructureLibrary\n",
    "from diffsims.generators.diffraction_generator import DiffractionGenerator\n",
    "from diffsims.generators.library_generator import DiffractionLibraryGenerator, VectorLibraryGenerator\n",
    "from pyxem.utils.sim_utils import sim_as_signal\n",
    "import tqdm\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### Variables\n",
    "\n",
    "# Paths\n",
    "root = r'C:\\Users\\Sauron\\Documents\\jf631\\SED_scripts'\n",
    "structures_path = os.path.join(root, 'nn_models/crystal_phases')\n",
    "phase_files = ['cubic_fapbi_scaled.cif', 'pbi2.cif', 'pbbr2.cif', 'pb.cif', 'gratia_4h.cif', 'gratia_6h.cif']\n",
    "\n",
    "# Calibration values\n",
    "calibration = 0.0045\n",
    "\n",
    "# Processing values\n",
    "n_angle_points = 500\n",
    "\n",
    "# Domain amplification\n",
    "simulated_direct_beam_bool = [False,]\n",
    "relrod_list = [0.002, 0.02, 0.03]\n",
    "spot_spread_list = [0.006, 0.014, 0.022]\n",
    "\n",
    "# Simulation microscope values (for azimuthal integration)\n",
    "detector_size = 515 #px\n",
    "beam_energy = 200.0 #keV\n",
    "wavelength = 2.5079e-12 #m\n",
    "detector_pix_size = 55e-6 #m\n",
    "from pyxem.detectors import Medipix515x515Detector\n",
    "detector = Medipix515x515Detector()\n",
    "\n",
    "# Data corruption\n",
    "#corrupt_n_times = 2\n",
    "\n",
    "# Noise addition values (do not change)\n",
    "include_also_non_noisy_simulation = True\n",
    "snrs = [0.9, 0.99]\n",
    "intensity_spikes = [0.25,]\n",
    "\n",
    "# Cropping and post-processing\n",
    "cropping_start = 0.11\n",
    "cropping_stop = 1.30\n",
    "sqrt_signal = False\n",
    "cropped_signal_points = 182 # To rebin signal, if necessary\n",
    "\n",
    "# Background parameterisation values (A: pre-exp factor, tau: decay time constant)\n",
    "a_vals = [0.5, 1., 2., 5.]\n",
    "tau_vals = [0.5, 1, 1.5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx amount of 2D diffraction patterns that will be produced: 54000\n",
      "Approx memory needed: 57.2886 GB\n"
     ]
    }
   ],
   "source": [
    "val = n_angle_points * len(phase_files) * len(relrod_list) * len(spot_spread_list) * len(snrs) * len(intensity_spikes)\n",
    "print('Approx amount of 2D diffraction patterns that will be produced: {}'.format(val))\n",
    "memory = detector_size**2 * val * 4 / 1e9  #4 bytes per float32 value\n",
    "print('Approx memory needed: {} GB'.format(memory))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulate data for each phase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_phases = 6\n"
     ]
    }
   ],
   "source": [
    "phase_dict = {}\n",
    "for phase in phase_files:\n",
    "    name = phase.split(\".\")[0]\n",
    "    phase_dict[name] = diffpy.structure.loadStructure(os.path.join(structures_path, phase))\n",
    "\n",
    "print('n_phases = {}'.format(len(phase_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_euler(npoints):\n",
    "    radius = 1\n",
    "    np.random.seed(1)\n",
    "    u = np.random.randint(-100,100+1,size=(npoints,))/100 \n",
    "    u2 = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    theta = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    x = radius*np.sqrt(1-u**2)*np.cos(theta)\n",
    "    y = radius*np.sqrt(1-u**2)*np.sin(theta)\n",
    "    z = radius*u \n",
    "    phi = np.arccos(z/radius)\n",
    "    eulerAlpha = u2\n",
    "    eulerBeta = phi\n",
    "    eulerGamma = theta\n",
    "    return np.array([np.rad2deg(eulerAlpha),np.rad2deg(eulerBeta),np.rad2deg(eulerGamma)]).T \n",
    "\n",
    "\n",
    "def get_reciprocal_radius(detector_size, calibration):\n",
    "    half_pattern_size = detector_size // 2\n",
    "    reciprocal_radius = calibration * half_pattern_size\n",
    "    return reciprocal_radius\n",
    "\n",
    "\n",
    "def create_diffraction_library(phase_dict, euler_list,\n",
    "                                       beam_energy, relrod_length,\n",
    "                                       calibration, detector_size,\n",
    "                                       with_direct_beam):\n",
    "\n",
    "    phase_names = list(phase_dict.keys())\n",
    "    phases = list(phase_dict.values())\n",
    "    euler_list_n = [euler_list, ] * len(phase_names)\n",
    "\n",
    "    sample_lib = StructureLibrary(phase_names, phases, euler_list_n)\n",
    "    ediff = DiffractionGenerator(beam_energy, relrod_length)\n",
    "    diff_gen = DiffractionLibraryGenerator(ediff)\n",
    "\n",
    "    reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "    library = diff_gen.get_diffraction_library(sample_lib,\n",
    "                                               calibration=calibration,\n",
    "                                               reciprocal_radius=reciprocal_radius,\n",
    "                                               half_shape=(detector_size//2, detector_size//2),\n",
    "                                               with_direct_beam=with_direct_beam)\n",
    "    return library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture\n",
    "data = {}\n",
    "for key, val in phase_dict.items():\n",
    "    data[key] = []\n",
    "for with_direct_beam in simulated_direct_beam_bool:\n",
    "    for relrod_length in tqdm.tqdm(relrod_list):\n",
    "        for spot_spread in spot_spread_list:\n",
    "\n",
    "            euler_list = get_random_euler(n_angle_points)\n",
    "\n",
    "            library = create_diffraction_library(phase_dict, euler_list,\n",
    "                                                 beam_energy, relrod_length,\n",
    "                                                 calibration, detector_size,\n",
    "                                                 with_direct_beam)\n",
    "\n",
    "            reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "            for euler in euler_list:\n",
    "                for phase in library.keys():\n",
    "                    pattern = sim_as_signal(library.get_library_entry(phase=phase,\n",
    "                                                                      angle=euler)['Sim'],\n",
    "                                            detector_size, spot_spread, reciprocal_radius)\n",
    "\n",
    "                    data[phase].append(pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LazyElectronDiffraction2D, title: , dimensions: (4500, 6|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "# Stack data\n",
    "import dask.array as da\n",
    "\n",
    "for i, value in enumerate(data.values()):\n",
    "    list_data = da.from_array([x.data for x in value], chunks=(10, detector_size, detector_size))\n",
    "\n",
    "    if i ==0:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = list_data\n",
    "    else:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = da.vstack([training_data, list_data],)\n",
    "\n",
    "del data\n",
    "del library\n",
    "del list_data\n",
    "gc.collect()\n",
    "\n",
    "shape = (len(phase_dict.keys()),\n",
    "         n_angle_points*len(relrod_list)*len(spot_spread_list)*len(simulated_direct_beam_bool),\n",
    "         detector_size,\n",
    "         detector_size)\n",
    "\n",
    "training_data = training_data.reshape(shape)\n",
    "training_data = pxm.LazyElectronDiffraction2D(training_data)\n",
    "training_data.set_diffraction_calibration(calibration)\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recenter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1435: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1435: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  9.4s\n",
      "<ElectronDiffraction2D, title: , dimensions: (4500, 6|515, 515)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=27000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5eb02fcb3f846a8927bccd30741fccf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shiftList = np.zeros((np.size(training_data.data,0),\n",
    "                      np.size(training_data.data,1),\n",
    "                      2,)\n",
    "                     )\n",
    "\n",
    "shiftList[:,:,0]=0.5\n",
    "shiftList[:,:,1]=0.5\n",
    "\n",
    "shiftList = shiftList.reshape(-1, shiftList.shape[-1]) # Flatten the 2D navigtion axis\n",
    "\n",
    "training_data.compute()\n",
    "training_data.align2D(shifts=shiftList,crop=False,fill_value=0., parallel=True)\n",
    "\n",
    "name = '2D_simulated_data_{}classes_{}neuler_domainrand_centered_{}cal.hspy'.format(np.size(training_data.data,0),  n_angle_points, calibration)\n",
    "#training_data.save(os.path.join('2d_simulated_data', name))\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add noise\n",
    "\n",
    "In two steps:\n",
    "- S&P noise\n",
    "- Poisson noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def add_noise_to_simulation(simulation_arr, snr, int_salt,):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Salt and pepper\n",
    "    def addsalt_pepper(dp_arr, snr, int_min = 0, int_max = int_salt,):\n",
    "\n",
    "        p0 = snr\n",
    "        # Add noise\n",
    "        size = np.shape(dp_arr)\n",
    "        mask = np.random.choice(a=(0, 1, 2),\n",
    "                                size=size,\n",
    "                                p=[p0, (1 - p0) / 2., (1 - p0) / 2.])\n",
    "\n",
    "        im = dp_arr.copy()\n",
    "        #im[mask == 1] = int_min # salt noise\n",
    "        im[mask == 2] = int_max # pepper noise\n",
    "\n",
    "        return im\n",
    "\n",
    "    # Add poisson noise on sp noise and normalise\n",
    "    im = simulation_arr.copy()\n",
    "    im += np.random.poisson(im)\n",
    "    im = im / im.max()\n",
    "\n",
    "    # Add bright spots randomly accross detector\n",
    "    im_sp = addsalt_pepper(im, snr,)\n",
    "\n",
    "    return im_sp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=27000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e494b7e72c324c16be9d716fb74e0d17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=27000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8de7e4a834064bdeaacb831700601241"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the noise addition function on signal\n",
    "\n",
    "training_data_noisy = []\n",
    "\n",
    "# Include the non-corrupted data in the dataset?\n",
    "if include_also_non_noisy_simulation:\n",
    "    training_data_noisy.append(training_data)\n",
    "\n",
    "# Append noisy data\n",
    "for snr in snrs:\n",
    "    for int_spike in intensity_spikes:\n",
    "\n",
    "        signal_noisy = training_data.map(add_noise_to_simulation,\n",
    "                                         snr=snr, int_salt=int_spike,\n",
    "                                         inplace=False, parallel=True)\n",
    "\n",
    "        training_data_noisy.append(signal_noisy)\n",
    "\n",
    "del training_data\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.8s\n",
      "<ElectronDiffraction2D, title: , dimensions: (13500, 6|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "training_data_noisy = hs.stack(training_data_noisy, axis=0)\n",
    "print(training_data_noisy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrate radially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10.269911516467715]\n",
      "<ElectronDiffraction1D, title: , dimensions: (13500, 6|256)>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=81000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27907a8eec1645ea8db17af685627e02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1534"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_length = detector_pix_size / (wavelength * calibration * 1e10)\n",
    "training_data_noisy.unit = \"k_A^-1\"\n",
    "training_data_noisy.set_experimental_parameters(beam_energy=beam_energy)\n",
    "radial_steps = np.ceil((int(detector_size/2) - 1)/2)*2\n",
    "training_data_1D = training_data_noisy.get_azimuthal_integral1d(npt_rad=radial_steps,\n",
    "                                                          center=([detector_size/2,detector_size/2]),\n",
    "                                                          detector=detector,\n",
    "                                                          detector_dist=camera_length,\n",
    "                                                          map_kwargs={'parallel':True})\n",
    "print(training_data_1D)\n",
    "\n",
    "del training_data_noisy\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop, normalise, sqrt, and rebin"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 13500, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Crop\n",
    "training_data_1D.crop_signal1D(cropping_start, cropping_stop)\n",
    "\n",
    "# Rebin\n",
    "scale_rebin = training_data_1D.data.shape[-1] / cropped_signal_points\n",
    "scale_rebin\n",
    "training_data_1D = training_data_1D.rebin(scale=(1,1,scale_rebin))\n",
    "\n",
    "if sqrt_signal:\n",
    "    training_data_1D.data = np.sqrt(training_data_1D.data)\n",
    "\n",
    "dpmax = training_data_1D.data.max(2)\n",
    "training_data_1D_norm = training_data_1D.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "print(training_data_1D_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add simulated background\n",
    "\n",
    "Approximate background as a $A*exp^{(-tau \\: q)}$ value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def add_background_to_signal1d_array(normalised_1d_sim_data_array, x_axis,\n",
    "                                     a_val, tau_val, bkg_function='exp_decay'):\n",
    "    \"\"\"\n",
    "    :param normalised_1d_sim_data_array:\n",
    "        The normalised 1d signal array (nav axis should be (points, phases, q))\n",
    "    :param x_axis: array of the actual q values\n",
    "        The A and tau values are optimised for 1/A-1 magnitude\n",
    "    :return: extended signal with new sets of sim data without and with bakgrounds\n",
    "    \"\"\"\n",
    "    def inv_q(x, A, tau):\n",
    "        return A * x**(-tau)\n",
    "\n",
    "    def exp_decay(x, A, tau):\n",
    "        return A * np.exp(- tau * x)\n",
    "\n",
    "    if bkg_function == 'exp_decay':\n",
    "        bkg = exp_decay(x_axis, a_val, tau_val)\n",
    "    elif bkg_function == 'inv_q':\n",
    "        bkg = inv_q(x_axis, a_val, tau_val)\n",
    "\n",
    "    s = normalised_1d_sim_data_array + bkg\n",
    "    return s\n",
    "\n",
    "\n",
    "# Expand datasets by copying and adding bkg\n",
    "training_data_1D_norm_bkg = training_data_1D_norm\n",
    "\n",
    "# Get the x-axis values from which to calculate bkg\n",
    "qs = training_data_1D.axes_manager.signal_axes[0].axis\n",
    "\n",
    "# Add bkg to signal\n",
    "for a in a_vals:\n",
    "    for tau in tau_vals:\n",
    "        bkg_data = add_background_to_signal1d_array(training_data_1D_norm, qs, a, tau)\n",
    "        training_data_1D_norm_bkg = np.hstack((training_data_1D_norm_bkg, bkg_data))\n",
    "\n",
    "# Renormalise data\n",
    "dpmax = training_data_1D_norm_bkg.max(-1)\n",
    "training_data_1D_norm_bkg_norm = training_data_1D_norm_bkg/dpmax[:,:,np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(6, 175500, 182)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_1D_norm_bkg_norm.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN requirements: reshape and labelling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1053000, 182)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_norm_bkg_norm = training_data_1D_norm_bkg_norm.reshape(-1, training_data_1D_norm_bkg_norm.shape[-1])\n",
    "\n",
    "print(training_data_1D_norm_bkg_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(1053000,)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels\n",
    "n_phases = len(phase_dict)\n",
    "labels = np.zeros((n_phases, int(training_data_1D_norm_bkg_norm.shape[0]/n_phases)))\n",
    "for i in range(n_phases):\n",
    "    labels[i,:] = i\n",
    "\n",
    "training_labels = labels.flatten()\n",
    "training_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037907, 182) (1037907,)\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers and nan values\n",
    "where_nan = np.argwhere(np.isnan(training_data_1D_norm_bkg_norm))\n",
    "training_data_1D_norm_bkg_norm = np.delete(training_data_1D_norm_bkg_norm, where_nan[:,0], axis = 0)\n",
    "training_labels = np.delete(training_labels, where_nan[:,0], axis = 0)\n",
    "print(training_data_1D_norm_bkg_norm.shape, training_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_norm_bkg_norm\n",
    "y = training_labels\n",
    "phase_names = list(phase_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('1D_simulated_data_cal{}_{}classes_{}neuler_domainrand_noisy_bkg'.format(calibration,\n",
    "                                                                              n_phases,\n",
    "                                                                        n_angle_points,),\n",
    "         x=x, y=y, phases=phase_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Misc data\n",
    "\n",
    "Radial integration in parallel"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "# Define function\n",
    "\n",
    "def integration_in_parallel_from_array(array_im, calibration, param_dict, return_hspy_object=False):\n",
    "    \"\"\"\n",
    "    array_im: single image array\n",
    "    param_dic: dictionary containing:\n",
    "        detector_pix_size, wavelength, beam_energy, detector_size, detector\n",
    "    \"\"\"\n",
    "    # import_packages\n",
    "    import pyxem as pxm\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    from pyxem.detectors import Medipix515x515Detector, Medipix256x256Detector, GenericFlatDetector\n",
    "\n",
    "    detector_size = param_dict['detector_size']\n",
    "    detector_pix_size = param_dict['detector_pix_size']\n",
    "    wavelength = param_dict['wavelength']\n",
    "    beam_energy = param_dict['beam_energy']\n",
    "    detector = param_dict['detector']\n",
    "\n",
    "    dp = pxm.signals.electron_diffraction2d.ElectronDiffraction2D(array_im)\n",
    "\n",
    "    camera_length =  detector_pix_size / (wavelength * calibration * 1e10)\n",
    "    dp.beam_energy = beam_energy\n",
    "    dp.set_diffraction_calibration(calibration)\n",
    "    dp.unit = 'k_A^-1'\n",
    "    radial_steps = np.ceil((int(detector_size/2) - 1)/2)*2\n",
    "    dp.set_experimental_parameters(beam_energy=beam_energy)\n",
    "\n",
    "    radial = dp.get_azimuthal_integral1d(npt_rad=radial_steps,\n",
    "                                         center=([detector_size/2,detector_size/2]),\n",
    "                                         detector=detector,\n",
    "                                         detector_dist=camera_length)\n",
    "\n",
    "    del dp\n",
    "    del array_im\n",
    "    gc.collect()\n",
    "\n",
    "    if return_hspy_object:\n",
    "        return radial\n",
    "    else:\n",
    "        return radial.data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "# Define parameters\n",
    "param_dict = {\n",
    "    'detector_pix_size': detector_pix_size,\n",
    "    'wavelength': wavelength,\n",
    "    'beam_energy': beam_energy,\n",
    "    'detector_size': detector_size,\n",
    "    'detector': detector,\n",
    "}\n",
    "\n",
    "calibration_arr = [calibration, ]\n",
    "param_dict_arr = [param_dict,]\n",
    "\n",
    "# Create iteration tools\n",
    "from itertools import product\n",
    "\n",
    "iterations = product(training_data_noisy.data, calibration_arr, param_dict_arr)\n",
    "\n",
    "# Run\n",
    "# make sure to always use multiprocess\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "\n",
    "# start your parallel workers at the beginning of your script\n",
    "n_cores = psutil.cpu_count(logical=False)\n",
    "pool = Pool(n_cores)\n",
    "\n",
    "# execute a computation(s) in parallel\n",
    "im_stack_radial = pool.starmap(integration_in_parallel_from_array, iterations)\n",
    "\n",
    "# turn off your parallel workers at the end of your script\n",
    "pool.close()\n",
    "\n",
    "np.shape(im_stack_radial)\n",
    "\n",
    "## Crop and normalise and sqrt\n",
    "\n",
    "calibration_radial_file = integration_in_parallel_from_array(training_data_noisy.inav[-1,-1].data,\n",
    "                                                             calibration, param_dict,\n",
    "                                                             return_hspy_object=True)\n",
    "\n",
    "training_data_1D_corrupted = pxm.ElectronDiffraction1D(im_stack_radial,)\n",
    "training_data_1D_corrupted.axes_manager.signal_axes[0].scale = calibration_radial_file.axes_manager.signal_axes[0].scale\n",
    "training_data_1D_corrupted.axes_manager.signal_axes[0].offset = calibration_radial_file.axes_manager.signal_axes[0].offset\n",
    "\n",
    "\n",
    "training_data_1D_corrupted.crop_signal1D(cropping_start, cropping_stop)\n",
    "\n",
    "if sqrt_signal:\n",
    "    training_data_1D_corrupted.data = np.sqrt(training_data_1D_corrupted.data)\n",
    "\n",
    "dpmax = training_data_1D_corrupted.data.max(2)\n",
    "training_data_1D_norm = training_data_1D_corrupted.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "print(training_data_1D_norm.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}