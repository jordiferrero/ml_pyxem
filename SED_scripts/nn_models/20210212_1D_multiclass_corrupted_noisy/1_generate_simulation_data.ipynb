{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create simualted datasets\n",
    "\n",
    "For both the training and testing datasets.\n",
    "\n",
    "The processing steps include:\n",
    "- Domain randomisation (relrod, spot_spread)\n",
    "- Multiple phases\n",
    "- Corruption of data (disabled for this example)\n",
    "- Adding nose (S&P)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.api:The ipywidgets GUI elements are not available, probably because the hyperspy_gui_ipywidgets package is not installed.\n",
      "WARNING:hyperspy.api:The traitsui GUI elements are not available, probably because the hyperspy_gui_traitsui package is not installed.\n",
      "WARNING:silx.opencl.common:Unable to import pyOpenCl. Please install it from: http://pypi.python.org/pypi/pyopencl\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import diffpy.structure\n",
    "from matplotlib import pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "from diffsims.libraries.structure_library import StructureLibrary\n",
    "from diffsims.generators.diffraction_generator import DiffractionGenerator\n",
    "from diffsims.generators.library_generator import DiffractionLibraryGenerator, VectorLibraryGenerator\n",
    "from pyxem.utils.sim_utils import sim_as_signal\n",
    "import tqdm\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "### Variables\n",
    "\n",
    "# Paths\n",
    "root = r'C:\\Users\\Sauron\\Documents\\jf631\\SED_scripts'\n",
    "structures_path = os.path.join(root, 'nn_models/crystal_phases')\n",
    "phase_files = ['cubic_fapbi_scaled.cif', 'pbi2.cif', 'pbbr2.cif', 'pb.cif', 'gratia_4h.cif', 'gratia_6h.cif']\n",
    "\n",
    "# Calibration values\n",
    "calibration = 0.0046\n",
    "\n",
    "# Domain amplification\n",
    "simulated_direct_beam_bool = [False,]\n",
    "relrod_list = [0.002, 0.02,]\n",
    "spot_spread_list = [0.01, 0.02]\n",
    "\n",
    "# Simulation microscope values\n",
    "detector_size = 515 #px\n",
    "beam_energy = 200.0 #keV\n",
    "wavelength = 2.5079e-12 #m\n",
    "detector_pix_size = 55e-6 #m\n",
    "from pyxem.detectors import Medipix515x515Detector\n",
    "detector = Medipix515x515Detector()\n",
    "\n",
    "# Processing values\n",
    "n_angle_points = 2\n",
    "#corrupt_n_times = 2\n",
    "\n",
    "cropping_start = 0.11\n",
    "cropping_stop = 1.30\n",
    "sqrt_signal = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulate data for each phase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_phases = 6\n"
     ]
    }
   ],
   "source": [
    "phase_dict = {}\n",
    "for phase in phase_files:\n",
    "    name = phase.split(\".\")[0]\n",
    "    phase_dict[name] = diffpy.structure.loadStructure(os.path.join(structures_path, phase))\n",
    "\n",
    "print('n_phases = {}'.format(len(phase_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_euler(npoints):\n",
    "    radius = 1\n",
    "    np.random.seed(1)\n",
    "    u = np.random.randint(-100,100+1,size=(npoints,))/100 \n",
    "    u2 = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    theta = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    x = radius*np.sqrt(1-u**2)*np.cos(theta)\n",
    "    y = radius*np.sqrt(1-u**2)*np.sin(theta)\n",
    "    z = radius*u \n",
    "    phi = np.arccos(z/radius)\n",
    "    eulerAlpha = u2\n",
    "    eulerBeta = phi\n",
    "    eulerGamma = theta\n",
    "    return np.array([np.rad2deg(eulerAlpha),np.rad2deg(eulerBeta),np.rad2deg(eulerGamma)]).T \n",
    "\n",
    "\n",
    "def get_reciprocal_radius(detector_size, calibration):\n",
    "    half_pattern_size = detector_size // 2\n",
    "    reciprocal_radius = calibration * half_pattern_size\n",
    "    return reciprocal_radius\n",
    "\n",
    "\n",
    "def create_diffraction_library(phase_dict, euler_list,\n",
    "                                       beam_energy, relrod_length,\n",
    "                                       calibration, detector_size,\n",
    "                                       with_direct_beam):\n",
    "\n",
    "    phase_names = list(phase_dict.keys())\n",
    "    phases = list(phase_dict.values())\n",
    "    euler_list_n = [euler_list, ] * len(phase_names)\n",
    "\n",
    "    sample_lib = StructureLibrary(phase_names, phases, euler_list_n)\n",
    "    ediff = DiffractionGenerator(beam_energy, relrod_length)\n",
    "    diff_gen = DiffractionLibraryGenerator(ediff)\n",
    "\n",
    "    reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "    library = diff_gen.get_diffraction_library(sample_lib,\n",
    "                                               calibration=calibration,\n",
    "                                               reciprocal_radius=reciprocal_radius,\n",
    "                                               half_shape=(detector_size//2, detector_size//2),\n",
    "                                               with_direct_beam=with_direct_beam)\n",
    "    return library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.42it/s]\u001B[A\n",
      "                                             \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.14it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "                                     \u001B[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This class changed in v0.3 and no longer takes a maximum_excitation_error\n",
      "This class changed in v0.3 and no longer takes a maximum_excitation_error\n",
      "This class changed in v0.3 and no longer takes a maximum_excitation_error\n",
      "This class changed in v0.3 and no longer takes a maximum_excitation_error\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for key, val in phase_dict.items():\n",
    "    data[key] = []\n",
    "for with_direct_beam in simulated_direct_beam_bool:\n",
    "    for relrod_length in tqdm.tqdm(relrod_list):\n",
    "        for spot_spread in spot_spread_list:\n",
    "\n",
    "            euler_list = get_random_euler(n_angle_points)\n",
    "\n",
    "            library = create_diffraction_library(phase_dict, euler_list,\n",
    "                                                 beam_energy, relrod_length,\n",
    "                                                 calibration, detector_size,\n",
    "                                                 with_direct_beam)\n",
    "\n",
    "            reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "            for euler in euler_list:\n",
    "                for phase in library.keys():\n",
    "                    pattern = sim_as_signal(library.get_library_entry(phase=phase,\n",
    "                                                                      angle=euler)['Sim'],\n",
    "                                            detector_size, spot_spread, reciprocal_radius)\n",
    "\n",
    "                    data[phase].append(pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LazyElectronDiffraction2D, title: , dimensions: (8, 6|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "# Stack data\n",
    "import dask.array as da\n",
    "\n",
    "for i, value in enumerate(data.values()):\n",
    "    list_data = da.from_array([x.data for x in value], chunks=(10, detector_size, detector_size))\n",
    "\n",
    "    if i ==0:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = list_data\n",
    "    else:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = da.vstack([training_data, list_data],)\n",
    "\n",
    "del data\n",
    "del library\n",
    "del list_data\n",
    "gc.collect()\n",
    "\n",
    "shape = (len(phase_dict.keys()),\n",
    "         n_angle_points*len(relrod_list)*len(spot_spread_list)*len(simulated_direct_beam_bool),\n",
    "         detector_size,\n",
    "         detector_size)\n",
    "\n",
    "training_data = training_data.reshape(shape)\n",
    "training_data = pxm.LazyElectronDiffraction2D(training_data)\n",
    "training_data.set_diffraction_calibration(calibration)\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recenter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "<ElectronDiffraction2D, title: , dimensions: (8, 6|515, 515)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1435: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1435: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=48.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5700fc2a8c0a4fa4b6e444e7a469b4c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shiftList = np.zeros((np.size(training_data.data,0),\n",
    "                      np.size(training_data.data,1),\n",
    "                      2,)\n",
    "                     )\n",
    "\n",
    "shiftList[:,:,0]=0.5\n",
    "shiftList[:,:,1]=0.5\n",
    "\n",
    "shiftList = shiftList.reshape(-1, shiftList.shape[-1]) # Flatten the 2D navigtion axis\n",
    "\n",
    "training_data.compute()\n",
    "training_data.align2D(shifts=shiftList,crop=False,fill_value=0., parallel=True)\n",
    "\n",
    "name = '2D_simulated_data_{}classes_{}neuler_domainrand_centered_{}cal.hspy'.format(np.size(training_data.data,0),  n_angle_points, calibration)\n",
    "#training_data.save(os.path.join('2d_simulated_data', name))\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(6, 8, 515, 515)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add noise\n",
    "\n",
    "In two steps:\n",
    "- S&P noise\n",
    "- Poisson noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def add_noise_to_simulation(simulation_arr, snr, int_salt, pdf_scaling_factor,):\n",
    "\n",
    "    from scipy.stats import multivariate_normal\n",
    "    import numpy as np\n",
    "\n",
    "    # Functions\n",
    "    def random_choice(p):\n",
    "        return np.random.choice((0, 1, 2), p=[p, (1 - p) / 2., (1 - p) / 2.])\n",
    "\n",
    "    # To speed up\n",
    "    random_choice_vec = np.vectorize(random_choice)\n",
    "\n",
    "    # Salt and pepper\n",
    "    def addsalt_pepper(im, snr, pdf_scale_fact,  pdf_func = 'gaussian', int_min = 0, int_max = 1, quantile_n=0.99):\n",
    "\n",
    "        # Create detector pixels matrix\n",
    "        xlen, ylen = im.shape\n",
    "        x, y = np.mgrid[0:xlen:1, 0:ylen:1]\n",
    "        pos = np.dstack((x, y))\n",
    "        det_center = (int(xlen/2), int(ylen/2))\n",
    "\n",
    "        # Create probability shape function for the random choise probability accross the 2D detector\n",
    "        if pdf_func == 'gaussian':\n",
    "            # Create Gaussian pdf from detector size\n",
    "            covar = np.zeros((2, 2))\n",
    "            np.fill_diagonal(covar, xlen * 3) # is HARD CODED VALUE FOR DETECTOR (TO MATCH EXP DATA)\n",
    "            rv = multivariate_normal(det_center, covar)\n",
    "            pdf = rv.pdf(pos)\n",
    "\n",
    "        if pdf_func == 'inv_quadratic':\n",
    "            # Create 1/q^2 pdf from detector size\n",
    "            def f_inv_q2(mesh, quantile_n):\n",
    "                mesh[mesh == 0] = 1e-1\n",
    "                x = mesh[:,:,0]\n",
    "                y = mesh[:,:,1]\n",
    "                # Get the q^2 ratio\n",
    "                z = 1 / (x**2 + y**2)\n",
    "                # Simulate detector saturation\n",
    "                quantile = np.quantile(z, q=quantile_n)\n",
    "                z[z > quantile] = quantile\n",
    "                z = z / z.max()\n",
    "                return z\n",
    "\n",
    "            pos_centre = (pos - det_center)\n",
    "            pdf = f_inv_q2(pos_centre, quantile_n)\n",
    "\n",
    "\n",
    "        # Normalise to snr so max val is snr\n",
    "        pdf *= snr / pdf.max()\n",
    "        # Create weighted probability array for choice 0 (no change)\n",
    "        p0 = np.ones(im.shape) * snr\n",
    "        # Subtract the effect the probabiliy of being off-centered following pdf function defined above\n",
    "        p0 -= pdf * pdf_scale_fact\n",
    "\n",
    "        # Add noise\n",
    "        mask = random_choice_vec(p0)\n",
    "\n",
    "        im[mask == 1] = int_min # salt noise\n",
    "        im[mask == 2] = int_max # pepper noise\n",
    "\n",
    "        return im\n",
    "\n",
    "    # Create saltpepper noise basis\n",
    "    im = simulation_arr\n",
    "    im_sp = addsalt_pepper(im, snr, pdf_scale_fact= pdf_scaling_factor, int_max=int_salt)\n",
    "\n",
    "    # Add poisson noise on sp noise\n",
    "    im = im_sp + np.random.poisson(im)\n",
    "\n",
    "    return im"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create iteration tools\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "# Variables\n",
    "sim_numpy_array = training_data.data\n",
    "sim_numpy_array = sim_numpy_array.reshape((sim_numpy_array.shape[0]*sim_numpy_array.shape[1], sim_numpy_array.shape[2], sim_numpy_array.shape[3]))\n",
    "\n",
    "snr_saltpepper = [0.99, 0.9999]\n",
    "intensity_salt = np.linspace(0.02, 0.1, 2)\n",
    "pdf_scaling_factor = np.linspace(0, 0.3, 2)\n",
    "\n",
    "\n",
    "iterations = product(sim_numpy_array, snr_saltpepper,\n",
    "                     intensity_salt, pdf_scaling_factor,)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# make sure to always use multiprocess\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "\n",
    "# start your parallel workers at the beginning of your script\n",
    "n_cores = psutil.cpu_count(logical=False)\n",
    "pool = Pool(n_cores)\n",
    "\n",
    "# execute a computation(s) in parallel\n",
    "im_stack = pool.starmap(add_noise_to_simulation, iterations)\n",
    "\n",
    "# turn off your parallel workers at the end of your script\n",
    "pool.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(12800, 515, 515)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(im_stack)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "how_many = 10\n",
    "f, ax = plt.subplots(ncols=how_many)\n",
    "for i,n in enumerate(np.random.randint(low=0, high=np.shape(im_stack)[0], size=how_many)):\n",
    "    ax[i].imshow(im_stack[n], vmax=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrate radially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Define function\n",
    "\n",
    "def integration_in_parallel_from_array(array_im, calibration, return_hspy_object=False):\n",
    "    \"\"\"\n",
    "    array_im: single image array\n",
    "    \"\"\"\n",
    "    # import_packages\n",
    "    import pyxem as pxm\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    from pyxem.detectors import Medipix515x515Detector\n",
    "\n",
    "    detector = Medipix515x515Detector()\n",
    "    dp = pxm.signals.electron_diffraction2d.ElectronDiffraction2D(array_im)\n",
    "\n",
    "    radial_int_points = 256\n",
    "    acceleration_v = 200\n",
    "    wavelength = 2.5079e-12\n",
    "    pix_size = 55e-6 #change to 1 if using the GenericFlatDetector()\n",
    "\n",
    "    camera_length = pix_size / (wavelength * calibration * 1e10)\n",
    "    dp.beam_energy = acceleration_v\n",
    "    dp.set_diffraction_calibration(calibration)\n",
    "    dp.unit = 'k_A^-1'\n",
    "    dp.set_experimental_parameters(beam_energy=acceleration_v)\n",
    "\n",
    "    radial = dp.get_azimuthal_integral1d(npt_rad=radial_int_points,\n",
    "                                         center=([dp.axes_manager.signal_shape[0]/2-1, dp.axes_manager.signal_shape[1]/2-1]),\n",
    "                                         detector=detector,\n",
    "                                         detector_dist=camera_length)\n",
    "\n",
    "    del dp\n",
    "    gc.collect()\n",
    "\n",
    "    if return_hspy_object:\n",
    "        return radial\n",
    "    else:\n",
    "        return radial.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "calibration = [0.0046, ]\n",
    "\n",
    "# Create iteration tools\n",
    "from itertools import product\n",
    "\n",
    "iterations = product(im_stack, calibration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Run\n",
    "# make sure to always use multiprocess\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "\n",
    "# start your parallel workers at the beginning of your script\n",
    "n_cores = psutil.cpu_count(logical=False)\n",
    "pool = Pool(n_cores)\n",
    "\n",
    "# execute a computation(s) in parallel\n",
    "im_stack_radial = pool.starmap(integration_in_parallel_from_array, iterations)\n",
    "\n",
    "# turn off your parallel workers at the end of your script\n",
    "pool.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(12800, 256)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(im_stack_radial)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corrupt data several times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def create_random_dampening_profile(signal_array):\n",
    "    sig_len = len(signal_array)\n",
    "    dumb = np.repeat(np.random.choice([0,1,1],38),(sig_len//50))\n",
    "    dumb1 = np.append(dumb,np.zeros([sig_len-len(dumb),]))\n",
    "    dumbrnd = np.repeat(np.random.rand(15,),sig_len//15)\n",
    "    dumbrnd1 = np.append(dumbrnd,np.zeros([sig_len-len(dumbrnd),]))\n",
    "    dempening_profile = dumb1 * dumbrnd1\n",
    "    return dempening_profile\n",
    "\n",
    "def dampen_signal(signal_array):\n",
    "    dampening_profile = create_random_dampening_profile(signal_array)\n",
    "    return signal_array * dampening_profile\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e63539588c294fe88a5539794c5287d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8b613de89b14bfeba69fd99a0a4cbbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data_1D_corrupted = training_data_1D.data\n",
    "\n",
    "for i in range(corrupt_n_times):\n",
    "    damped = training_data_1D.map(dampen_signal, inplace=False, parallel=True)\n",
    "    training_data_1D_corrupted = np.append(training_data_1D_corrupted, damped, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop and normalise and sqrt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9000, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_corrupted = pxm.ElectronDiffraction1D(training_data_1D_corrupted,)\n",
    "training_data_1D_corrupted.axes_manager.signal_axes[0].scale = training_data_1D.axes_manager.signal_axes[0].scale\n",
    "training_data_1D_corrupted.axes_manager.signal_axes[0].offset = training_data_1D.axes_manager.signal_axes[0].offset\n",
    "\n",
    "\n",
    "training_data_1D_corrupted.crop_signal1D(cropping_start, cropping_stop)\n",
    "\n",
    "if sqrt_signal:\n",
    "    training_data_1D_corrupted.data = np.sqrt(training_data_1D_corrupted.data)\n",
    "\n",
    "dpmax = training_data_1D_corrupted.data.max(2)\n",
    "training_data_1D_norm = training_data_1D_corrupted.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "print(training_data_1D_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN requirements: reshape and labelling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 182)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_norm = training_data_1D_norm.reshape(-1, training_data_1D_norm.shape[-1])\n",
    "\n",
    "print(training_data_1D_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Create labels\n",
    "n_phases = len(phase_dict)\n",
    "labels = np.zeros((n_phases, int(training_data_1D_norm.shape[0]/n_phases)))\n",
    "for i in range(n_phases):\n",
    "    labels[i,:] = i\n",
    "\n",
    "training_labels = labels.flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for outliers and nan values\n",
    "where_nan = np.argwhere(np.isnan(training_data_1D_norm))\n",
    "training_data_1D_norm = np.delete(training_data_1D_norm, where_nan[:,0], axis = 0)\n",
    "training_labels = np.delete(training_labels, where_nan[:,0], axis = 0)\n",
    "print(training_data_1D_norm.shape, training_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_norm\n",
    "y = training_labels\n",
    "phase_names = list(phase_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('1D_simulated_data_{}classes_{}neuler_domainrand_{}ncorrupted'.format(n_phases,  n_angle_points, corrupt_n_times), x=x, y=y, phases=phase_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_1D_corrupted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-290e6fd28dcf>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_data_1D_corrupted\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'training_data_1D_corrupted' is not defined"
     ]
    }
   ],
   "source": [
    "print(training_data_1D_corrupted.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}