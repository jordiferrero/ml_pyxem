{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create simualted datasets\n",
    "\n",
    "For both the training and testing datasets.\n",
    "\n",
    "The processing steps include:\n",
    "- Domain randomisation (relrod, spot_spread)\n",
    "- Multiple phases (6)\n",
    "- Corruption of data (disabled for this example)\n",
    "- Adding nose (S&P)\n",
    "- Adding background intensity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:silx.opencl.common:Unable to import pyOpenCl. Please install it from: http://pypi.python.org/pypi/pyopencl\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import diffpy.structure\n",
    "from matplotlib import pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "from diffsims.libraries.structure_library import StructureLibrary\n",
    "from diffsims.generators.diffraction_generator import DiffractionGenerator\n",
    "from diffsims.generators.library_generator import DiffractionLibraryGenerator, VectorLibraryGenerator\n",
    "from pyxem.utils.sim_utils import sim_as_signal\n",
    "import tqdm\n",
    "import gc\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### Variables\n",
    "\n",
    "# Paths\n",
    "root = r'C:\\Users\\Sauron\\Documents\\jf631\\SED_scripts'\n",
    "root = r'C:\\Users\\Sauron\\PycharmProjects\\ml_pyxem\\SED_scripts'\n",
    "structures_path = os.path.join(root, 'nn_models/crystal_phases')\n",
    "phase_files = ['p4mbm_tetragonal.cif',  'gratia_2h.cif', 'gratia_4h.cif', 'gratia_6h.cif', 'pbi2_2h.cif', 'pb.cif',]\n",
    "\n",
    "# Calibration values\n",
    "\n",
    "calibrations = [0.0056, 0.0058,]\n",
    "\n",
    "# Processing values\n",
    "n_angle_points = 600\n",
    "\n",
    "# Domain amplification\n",
    "simulated_direct_beam_bool = [False,]\n",
    "relrod_list = [0.002, 0.02, 0.03]\n",
    "spot_spread_list = [0.006, 0.014, 0.022]\n",
    "\n",
    "# Simulation microscope values (for azimuthal integration)\n",
    "detector_size = 515 #px\n",
    "beam_energy = 200.0 #keV\n",
    "wavelength = 2.5079e-12 #m\n",
    "detector_pix_size = 55e-6 #m\n",
    "from pyxem.detectors import Medipix515x515Detector\n",
    "detector = Medipix515x515Detector()\n",
    "\n",
    "# Data corruption\n",
    "#corrupt_n_times = 2\n",
    "\n",
    "# Noise addition values (do not change)\n",
    "include_also_non_noisy_simulation = True\n",
    "snrs = [0.9, 0.99]\n",
    "intensity_spikes = [0.25,]\n",
    "\n",
    "# Cropping and post-processing\n",
    "cropping_start_k = 0.11 #k units\n",
    "cropping_stop_k = 1.30 #k_units\n",
    "cropped_signal_k_points = 147 # To rebin signal, if necessary (when using k_units)\n",
    "\n",
    "cropping_start_px = 13.55 #pixels\n",
    "cropping_stop_px = 160.55 #pixels\n",
    "sqrt_signal = False\n",
    "\n",
    "\n",
    "# Background parameterisation values (A: pre-exp factor, tau: decay time constant)\n",
    "a_vals = [0.5, 1., 2., 5.]\n",
    "tau_vals = [0.5, 1, 1.5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx amount of 2D diffraction patterns that will be produced: 75600\n",
      "Approx memory needed: 80.20404 GB\n"
     ]
    }
   ],
   "source": [
    "val = n_angle_points * (len(phase_files) + 1)* len(relrod_list) * len(spot_spread_list) * len(snrs) * len(intensity_spikes)\n",
    "print('Approx amount of 2D diffraction patterns that will be produced: {}'.format(val))\n",
    "memory = detector_size**2 * val * 4 / 1e9  #4 bytes per float32 value\n",
    "print('Approx memory needed: {} GB'.format(memory))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rep 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "calibration = calibrations[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulate data for each phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_phases = 6\n"
     ]
    }
   ],
   "source": [
    "phase_dict = {}\n",
    "for phase in phase_files:\n",
    "    name = phase.split(\".\")[0]\n",
    "    phase_dict[name] = diffpy.structure.loadStructure(os.path.join(structures_path, phase))\n",
    "\n",
    "print('n_phases = {}'.format(len(phase_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_random_euler(npoints):\n",
    "    radius = 1\n",
    "    np.random.seed(1)\n",
    "    u = np.random.randint(-100,100+1,size=(npoints,))/100 \n",
    "    u2 = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    theta = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    x = radius*np.sqrt(1-u**2)*np.cos(theta)\n",
    "    y = radius*np.sqrt(1-u**2)*np.sin(theta)\n",
    "    z = radius*u \n",
    "    phi = np.arccos(z/radius)\n",
    "    eulerAlpha = u2\n",
    "    eulerBeta = phi\n",
    "    eulerGamma = theta\n",
    "    return np.array([np.rad2deg(eulerAlpha),np.rad2deg(eulerBeta),np.rad2deg(eulerGamma)]).T \n",
    "\n",
    "\n",
    "def get_reciprocal_radius(detector_size, calibration):\n",
    "    half_pattern_size = detector_size // 2\n",
    "    reciprocal_radius = calibration * half_pattern_size\n",
    "    return reciprocal_radius\n",
    "\n",
    "\n",
    "def create_diffraction_library(phase_dict, euler_list,\n",
    "                                       beam_energy, relrod_length,\n",
    "                                       calibration, detector_size,\n",
    "                                       with_direct_beam):\n",
    "\n",
    "    phase_names = list(phase_dict.keys())\n",
    "    phases = list(phase_dict.values())\n",
    "    euler_list_n = [euler_list, ] * len(phase_names)\n",
    "\n",
    "    sample_lib = StructureLibrary(phase_names, phases, euler_list_n)\n",
    "    ediff = DiffractionGenerator(beam_energy, relrod_length)\n",
    "    diff_gen = DiffractionLibraryGenerator(ediff)\n",
    "\n",
    "    reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "    library = diff_gen.get_diffraction_library(sample_lib,\n",
    "                                               calibration=calibration,\n",
    "                                               reciprocal_radius=reciprocal_radius,\n",
    "                                               half_shape=(detector_size//2, detector_size//2),\n",
    "                                               with_direct_beam=with_direct_beam)\n",
    "    return library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "%%capture\n",
    "data = {}\n",
    "for key, val in phase_dict.items():\n",
    "    data[key] = []\n",
    "for with_direct_beam in simulated_direct_beam_bool:\n",
    "    for relrod_length in tqdm.tqdm(relrod_list):\n",
    "        for spot_spread in spot_spread_list:\n",
    "\n",
    "            euler_list = get_random_euler(n_angle_points)\n",
    "\n",
    "            library = create_diffraction_library(phase_dict, euler_list,\n",
    "                                                 beam_energy, relrod_length,\n",
    "                                                 calibration, detector_size,\n",
    "                                                 with_direct_beam)\n",
    "\n",
    "            reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "            for euler in euler_list:\n",
    "                for phase in library.keys():\n",
    "                    pattern = sim_as_signal(library.get_library_entry(phase=phase,\n",
    "                                                                      angle=euler)['Sim'],\n",
    "                                            detector_size, spot_spread, reciprocal_radius)\n",
    "\n",
    "                    data[phase].append(pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LazyElectronDiffraction2D, title: , dimensions: (5400, 6|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "# Stack data\n",
    "import dask.array as da\n",
    "\n",
    "for i, value in enumerate(data.values()):\n",
    "    list_data = da.from_array([x.data for x in value], chunks=(10, detector_size, detector_size))\n",
    "\n",
    "    if i ==0:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = list_data\n",
    "    else:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = da.vstack([training_data, list_data],)\n",
    "\n",
    "del data\n",
    "del library\n",
    "del list_data\n",
    "gc.collect()\n",
    "\n",
    "shape = (len(phase_dict.keys()),\n",
    "         n_angle_points*len(relrod_list)*len(spot_spread_list)*len(simulated_direct_beam_bool),\n",
    "         detector_size,\n",
    "         detector_size)\n",
    "\n",
    "training_data = training_data.reshape(shape)\n",
    "training_data = pxm.LazyElectronDiffraction2D(training_data)\n",
    "training_data.set_diffraction_calibration(calibration)\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recenter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1467: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1467: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12.1s\n",
      "<ElectronDiffraction2D, title: , dimensions: (5400, 6|515, 515)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa5c2aca490c4caca8c57a6ba9681f1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shiftList = np.zeros((np.size(training_data.data,0),\n",
    "                      np.size(training_data.data,1),\n",
    "                      2,)\n",
    "                     )\n",
    "\n",
    "shiftList[:,:,0]=0.5\n",
    "shiftList[:,:,1]=0.5\n",
    "\n",
    "shiftList = shiftList.reshape(-1, shiftList.shape[-1]) # Flatten the 2D navigtion axis\n",
    "\n",
    "training_data.compute()\n",
    "training_data.align2D(shifts=shiftList,crop=False,fill_value=0., parallel=True)\n",
    "\n",
    "#name = '2D_simulated_data_{}classes_{}neuler_domainrand_centered_{}cal.hspy'.format(np.size(training_data.data,0),  n_angle_points, calibration)\n",
    "#training_data.save(os.path.join('2d_simulated_data', name))\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add background phase (without signal)\n",
    "\n",
    "Create a blank detector in which noise and a bkg will be added."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.2s\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": "(7, 5400, 515, 515)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add phase in the dictionary\n",
    "phase_dict['bkg_phase'] = []\n",
    "\n",
    "# Create blank datector\n",
    "shape_blank = np.shape(training_data,)[1:]\n",
    "shape_blank = (1,) + shape_blank\n",
    "blank = pxm.signals.electron_diffraction2d.ElectronDiffraction2D(np.zeros(shape_blank))\n",
    "training_data = hs.stack([training_data, blank], axis=1)\n",
    "\n",
    "print(len(phase_dict))\n",
    "training_data.data.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add noise\n",
    "\n",
    "In two steps:\n",
    "- S&P noise\n",
    "- Poisson noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_noise_to_simulation(simulation_arr, snr, int_salt,):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Salt and pepper\n",
    "    def addsalt_pepper(dp_arr, snr, int_min = 0, int_max = int_salt,):\n",
    "\n",
    "        p0 = snr\n",
    "        # Add noise\n",
    "        size = np.shape(dp_arr)\n",
    "        mask = np.random.choice(a=(0, 1, 2),\n",
    "                                size=size,\n",
    "                                p=[p0, (1 - p0) / 2., (1 - p0) / 2.])\n",
    "\n",
    "        im = dp_arr.copy()\n",
    "        #im[mask == 1] = int_min # salt noise\n",
    "        im[mask == 2] = int_max # pepper noise\n",
    "\n",
    "        return im\n",
    "\n",
    "    # Add poisson noise on sp noise and normalise\n",
    "    im = simulation_arr.copy()\n",
    "    im += np.random.poisson(im)\n",
    "\n",
    "    max = im.max()\n",
    "    if max == 0:\n",
    "        im = im\n",
    "    else:\n",
    "        im = im / im.max()\n",
    "\n",
    "    # Add bright spots randomly accross detector\n",
    "    im_sp = addsalt_pepper(im, snr,)\n",
    "\n",
    "    return im_sp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/37800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2713697edebd41f489002da5b9a9240a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35992f9ffe174c66811e951b699004af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the noise addition function on signal\n",
    "\n",
    "training_data_noisy = []\n",
    "\n",
    "# Include the non-corrupted data in the dataset?\n",
    "if include_also_non_noisy_simulation:\n",
    "    training_data_noisy.append(training_data)\n",
    "\n",
    "# Append noisy data\n",
    "for snr in snrs:\n",
    "    for int_spike in intensity_spikes:\n",
    "\n",
    "        signal_noisy = training_data.map(add_noise_to_simulation,\n",
    "                                         snr=snr, int_salt=int_spike,\n",
    "                                         inplace=False, parallel=True)\n",
    "\n",
    "        training_data_noisy.append(signal_noisy)\n",
    "\n",
    "del training_data\n",
    "del signal_noisy\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.3s\n",
      "<ElectronDiffraction2D, title: , dimensions: (16200, 7|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "training_data_noisy = hs.stack(training_data_noisy, axis=0)\n",
    "print(training_data_noisy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrate radially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 12.775920463850575]\n",
      "<ElectronDiffraction1D, title: , dimensions: (16200, 7|256)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/113400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12b47afe736e4a5586a5af62bfdc3947"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1805"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_length = detector_pix_size / (wavelength * calibration * 1e10)\n",
    "training_data_noisy.unit = \"k_A^-1\"\n",
    "training_data_noisy.set_experimental_parameters(beam_energy=beam_energy)\n",
    "radial_steps = int(np.ceil((int(detector_size/2) - 1)/2)*2)\n",
    "training_data_1D = training_data_noisy.get_azimuthal_integral1d(npt_rad=radial_steps,\n",
    "                                                          center=([detector_size/2,detector_size/2]),\n",
    "                                                          detector=detector,\n",
    "                                                          detector_dist=camera_length,\n",
    "                                                          map_kwargs={'parallel':True})\n",
    "print(training_data_1D)\n",
    "\n",
    "del training_data_noisy\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalise (and sqrt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 16200, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Sqrt signal (if wanted)\n",
    "if sqrt_signal:\n",
    "    training_data_1D.data = np.sqrt(training_data_1D.data)\n",
    "\n",
    "# Normalise\n",
    "dpmax = training_data_1D.data.max(2)\n",
    "training_data_1D_norm = training_data_1D.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "# Correct any nan value\n",
    "nan_mask = np.isnan(training_data_1D_norm)\n",
    "training_data_1D_norm[nan_mask] = 0\n",
    "\n",
    "print(training_data_1D_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add simulated background\n",
    "\n",
    "Approximate background as a $A*exp^{(-tau \\: q)}$ value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 210600, 256)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_background_to_signal1d_array(normalised_1d_sim_data_array, x_axis,\n",
    "                                     a_val, tau_val, bkg_function='exp_decay'):\n",
    "    \"\"\"\n",
    "    :param normalised_1d_sim_data_array:\n",
    "        The normalised 1d signal array (nav axis should be (points, phases, q))\n",
    "    :param x_axis: array of the actual q values\n",
    "        The A and tau values are optimised for 1/A-1 magnitude\n",
    "    :return: extended signal with new sets of sim data without and with bakgrounds\n",
    "    \"\"\"\n",
    "    def inv_q(x, A, tau):\n",
    "        return A * x**(-tau)\n",
    "\n",
    "    def exp_decay(x, A, tau):\n",
    "        return A * np.exp(- tau * x)\n",
    "\n",
    "    if bkg_function == 'exp_decay':\n",
    "        bkg = exp_decay(x_axis, a_val, tau_val)\n",
    "    elif bkg_function == 'inv_q':\n",
    "        bkg = inv_q(x_axis, a_val, tau_val)\n",
    "\n",
    "    s = normalised_1d_sim_data_array + bkg\n",
    "    return s\n",
    "\n",
    "\n",
    "# Expand datasets by copying and adding bkg\n",
    "training_data_1D_norm_bkg = training_data_1D_norm\n",
    "\n",
    "# Get the x-axis values from which to calculate bkg\n",
    "qs = training_data_1D.axes_manager.signal_axes[0].axis\n",
    "\n",
    "# Add bkg to signal\n",
    "for a in a_vals:\n",
    "    for tau in tau_vals:\n",
    "        bkg_data = add_background_to_signal1d_array(training_data_1D_norm, qs, a, tau)\n",
    "        training_data_1D_norm_bkg = np.hstack((training_data_1D_norm_bkg, bkg_data))\n",
    "\n",
    "training_data_1D_norm_bkg.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop, rebin and renormalise\n",
    "\n",
    "Crop both in terms of q (rebin but no shift) and pixel values (shift but no rebin)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 210600, 147)\n",
      "(7, 210600, 147)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_norm_bkg = hs.signals.Signal1D(training_data_1D_norm_bkg)\n",
    "\n",
    "training_data_1D_px = training_data_1D_norm_bkg.deepcopy()\n",
    "\n",
    "# Recreate .hspy object to crop with k units\n",
    "scale = training_data_1D.axes_manager.signal_axes[0].scale\n",
    "offset = training_data_1D.axes_manager.signal_axes[0].offset\n",
    "training_data_1D_norm_bkg.axes_manager.signal_axes[0].scale = scale\n",
    "training_data_1D_norm_bkg.axes_manager.signal_axes[0].offset = offset\n",
    "\n",
    "training_data_1D_q = training_data_1D_norm_bkg.deepcopy()\n",
    "\n",
    "del training_data_1D\n",
    "del bkg_data\n",
    "del training_data_1D_norm\n",
    "del training_data_1D_norm_bkg\n",
    "gc.collect()\n",
    "\n",
    "# In k units:\n",
    "# Crop in k units\n",
    "training_data_1D_q.crop_signal1D(cropping_start_k, cropping_stop_k)\n",
    "# Rebin\n",
    "scale_rebin = training_data_1D_q.data.shape[-1] / cropped_signal_k_points\n",
    "scale_rebin\n",
    "training_data_1D_q = training_data_1D_q.rebin(scale=(1,1,scale_rebin))\n",
    "# Renormalise data\n",
    "dpmax = training_data_1D_q.data.max(-1)\n",
    "training_data_1D_q = training_data_1D_q.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "# In pixel units:\n",
    "# Crop in pixel units\n",
    "training_data_1D_px.crop_signal1D(cropping_start_px, cropping_stop_px)\n",
    "# Renormalise data\n",
    "dpmax = training_data_1D_px.data.max(-1)\n",
    "training_data_1D_px = training_data_1D_px.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "print(training_data_1D_q.shape)\n",
    "print(training_data_1D_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN requirements: reshape and labelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1474200, 147)\n",
      "(1474200, 147)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_q = training_data_1D_q.reshape(-1, training_data_1D_q.shape[-1])\n",
    "training_data_1D_px = training_data_1D_px.reshape(-1, training_data_1D_px.shape[-1])\n",
    "\n",
    "print(training_data_1D_q.shape)\n",
    "print(training_data_1D_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(1474200,)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels\n",
    "n_phases = len(phase_dict)\n",
    "labels = np.zeros((n_phases, int(training_data_1D_q.shape[0]/n_phases)))\n",
    "for i in range(n_phases):\n",
    "    labels[i,:] = i\n",
    "\n",
    "training_labels = labels.flatten()\n",
    "training_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1468764, 147) (1468764,)\n",
      "(1468743, 147) (1468743,)\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers and nan values\n",
    "where_nan_q = np.argwhere(np.isnan(training_data_1D_q))\n",
    "where_nan_px = np.argwhere(np.isnan(training_data_1D_px))\n",
    "\n",
    "training_data_1D_q = np.delete(training_data_1D_q, where_nan_q[:,0], axis = 0)\n",
    "training_labels_q = np.delete(training_labels, where_nan_q[:,0], axis = 0)\n",
    "\n",
    "training_data_1D_px = np.delete(training_data_1D_px, where_nan_px[:,0], axis = 0)\n",
    "training_labels_px = np.delete(training_labels, where_nan_px[:,0], axis = 0)\n",
    "\n",
    "print(training_data_1D_q.shape, training_labels_q.shape)\n",
    "print(training_data_1D_px.shape, training_labels_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p4mbm_tetragonal', 'gratia_2h', 'gratia_4h', 'gratia_6h', 'pbi2_2h', 'pb', 'bkg_phase']\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "phase_names = list(phase_dict.keys())\n",
    "\n",
    "print(phase_names)\n",
    "print(training_labels[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_q\n",
    "y = training_labels_q\n",
    "\n",
    "np.savez('1D_simulated_data_cal{}_cropK_{}classesInclBkg_{}neuler_domainrand_noisy_bkg'.format(calibration,\n",
    "                                                                              n_phases,\n",
    "                                                                        n_angle_points,),\n",
    "         x=x, y=y, phases=phase_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_px\n",
    "y = training_labels_px\n",
    "\n",
    "np.savez('1D_simulated_data_cal{}_cropPX_{}classesInclBkg_{}neuler_domainrand_noisy_bkg'.format(calibration,\n",
    "                                                                              n_phases,\n",
    "                                                                        n_angle_points,),\n",
    "         x=x, y=y, phases=phase_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "3088"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.figure()\n",
    "plt.plot(training_data_1D_px[i], label='px')\n",
    "plt.plot(training_data_1D_q[i], label='q')\n",
    "plt.legend()\n",
    "\n",
    "del training_data_1D_px\n",
    "del training_data_1D_q\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rep 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "calibration = calibrations[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulate data for each phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_phases = 6\n"
     ]
    }
   ],
   "source": [
    "phase_dict = {}\n",
    "for phase in phase_files:\n",
    "    name = phase.split(\".\")[0]\n",
    "    phase_dict[name] = diffpy.structure.loadStructure(os.path.join(structures_path, phase))\n",
    "\n",
    "print('n_phases = {}'.format(len(phase_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_random_euler(npoints):\n",
    "    radius = 1\n",
    "    np.random.seed(1)\n",
    "    u = np.random.randint(-100,100+1,size=(npoints,))/100\n",
    "    u2 = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    theta = 2*np.pi*np.random.random(size=(npoints,))\n",
    "    x = radius*np.sqrt(1-u**2)*np.cos(theta)\n",
    "    y = radius*np.sqrt(1-u**2)*np.sin(theta)\n",
    "    z = radius*u\n",
    "    phi = np.arccos(z/radius)\n",
    "    eulerAlpha = u2\n",
    "    eulerBeta = phi\n",
    "    eulerGamma = theta\n",
    "    return np.array([np.rad2deg(eulerAlpha),np.rad2deg(eulerBeta),np.rad2deg(eulerGamma)]).T\n",
    "\n",
    "\n",
    "def get_reciprocal_radius(detector_size, calibration):\n",
    "    half_pattern_size = detector_size // 2\n",
    "    reciprocal_radius = calibration * half_pattern_size\n",
    "    return reciprocal_radius\n",
    "\n",
    "\n",
    "def create_diffraction_library(phase_dict, euler_list,\n",
    "                                       beam_energy, relrod_length,\n",
    "                                       calibration, detector_size,\n",
    "                                       with_direct_beam):\n",
    "\n",
    "    phase_names = list(phase_dict.keys())\n",
    "    phases = list(phase_dict.values())\n",
    "    euler_list_n = [euler_list, ] * len(phase_names)\n",
    "\n",
    "    sample_lib = StructureLibrary(phase_names, phases, euler_list_n)\n",
    "    ediff = DiffractionGenerator(beam_energy, relrod_length)\n",
    "    diff_gen = DiffractionLibraryGenerator(ediff)\n",
    "\n",
    "    reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "    library = diff_gen.get_diffraction_library(sample_lib,\n",
    "                                               calibration=calibration,\n",
    "                                               reciprocal_radius=reciprocal_radius,\n",
    "                                               half_shape=(detector_size//2, detector_size//2),\n",
    "                                               with_direct_beam=with_direct_beam)\n",
    "    return library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "%%capture\n",
    "data = {}\n",
    "for key, val in phase_dict.items():\n",
    "    data[key] = []\n",
    "for with_direct_beam in simulated_direct_beam_bool:\n",
    "    for relrod_length in tqdm.tqdm(relrod_list):\n",
    "        for spot_spread in spot_spread_list:\n",
    "\n",
    "            euler_list = get_random_euler(n_angle_points)\n",
    "\n",
    "            library = create_diffraction_library(phase_dict, euler_list,\n",
    "                                                 beam_energy, relrod_length,\n",
    "                                                 calibration, detector_size,\n",
    "                                                 with_direct_beam)\n",
    "\n",
    "            reciprocal_radius = get_reciprocal_radius(detector_size, calibration)\n",
    "            for euler in euler_list:\n",
    "                for phase in library.keys():\n",
    "                    pattern = sim_as_signal(library.get_library_entry(phase=phase,\n",
    "                                                                      angle=euler)['Sim'],\n",
    "                                            detector_size, spot_spread, reciprocal_radius)\n",
    "\n",
    "                    data[phase].append(pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LazyElectronDiffraction2D, title: , dimensions: (5400, 6|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "# Stack data\n",
    "import dask.array as da\n",
    "\n",
    "for i, value in enumerate(data.values()):\n",
    "    list_data = da.from_array([x.data for x in value], chunks=(10, detector_size, detector_size))\n",
    "\n",
    "    if i ==0:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = list_data\n",
    "    else:\n",
    "        #list_data = np.expand_dims(list_data, 1)\n",
    "        training_data = da.vstack([training_data, list_data],)\n",
    "\n",
    "del data\n",
    "del library\n",
    "del list_data\n",
    "gc.collect()\n",
    "\n",
    "shape = (len(phase_dict.keys()),\n",
    "         n_angle_points*len(relrod_list)*len(spot_spread_list)*len(simulated_direct_beam_bool),\n",
    "         detector_size,\n",
    "         detector_size)\n",
    "\n",
    "training_data = training_data.reshape(shape)\n",
    "training_data = pxm.LazyElectronDiffraction2D(training_data)\n",
    "training_data.set_diffraction_calibration(calibration)\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recenter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1467: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\dask\\array\\core.py:1467: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12.0s\n",
      "<ElectronDiffraction2D, title: , dimensions: (5400, 6|515, 515)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f08f996b934a41fb9607085d5216b760"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shiftList = np.zeros((np.size(training_data.data,0),\n",
    "                      np.size(training_data.data,1),\n",
    "                      2,)\n",
    "                     )\n",
    "\n",
    "shiftList[:,:,0]=0.5\n",
    "shiftList[:,:,1]=0.5\n",
    "\n",
    "shiftList = shiftList.reshape(-1, shiftList.shape[-1]) # Flatten the 2D navigtion axis\n",
    "\n",
    "training_data.compute()\n",
    "training_data.align2D(shifts=shiftList,crop=False,fill_value=0., parallel=True)\n",
    "\n",
    "#name = '2D_simulated_data_{}classes_{}neuler_domainrand_centered_{}cal.hspy'.format(np.size(training_data.data,0),  n_angle_points, calibration)\n",
    "#training_data.save(os.path.join('2d_simulated_data', name))\n",
    "print(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add background phase (without signal)\n",
    "\n",
    "Create a blank detector in which noise and a bkg will be added."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.3s\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": "(7, 5400, 515, 515)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add phase in the dictionary\n",
    "phase_dict['bkg_phase'] = []\n",
    "\n",
    "# Create blank datector\n",
    "shape_blank = np.shape(training_data,)[1:]\n",
    "shape_blank = (1,) + shape_blank\n",
    "blank = pxm.signals.electron_diffraction2d.ElectronDiffraction2D(np.zeros(shape_blank))\n",
    "training_data = hs.stack([training_data, blank], axis=1)\n",
    "\n",
    "print(len(phase_dict))\n",
    "training_data.data.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add noise\n",
    "\n",
    "In two steps:\n",
    "- S&P noise\n",
    "- Poisson noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def add_noise_to_simulation(simulation_arr, snr, int_salt,):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Salt and pepper\n",
    "    def addsalt_pepper(dp_arr, snr, int_min = 0, int_max = int_salt,):\n",
    "\n",
    "        p0 = snr\n",
    "        # Add noise\n",
    "        size = np.shape(dp_arr)\n",
    "        mask = np.random.choice(a=(0, 1, 2),\n",
    "                                size=size,\n",
    "                                p=[p0, (1 - p0) / 2., (1 - p0) / 2.])\n",
    "\n",
    "        im = dp_arr.copy()\n",
    "        #im[mask == 1] = int_min # salt noise\n",
    "        im[mask == 2] = int_max # pepper noise\n",
    "\n",
    "        return im\n",
    "\n",
    "    # Add poisson noise on sp noise and normalise\n",
    "    im = simulation_arr.copy()\n",
    "    im += np.random.poisson(im)\n",
    "\n",
    "    max = im.max()\n",
    "    if max == 0:\n",
    "        im = im\n",
    "    else:\n",
    "        im = im / im.max()\n",
    "\n",
    "    # Add bright spots randomly accross detector\n",
    "    im_sp = addsalt_pepper(im, snr,)\n",
    "\n",
    "    return im_sp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/37800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "422b9642652b4b0982ea05e8786068d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e0386b4a2e94ce98cc19b1e9e406fe5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the noise addition function on signal\n",
    "\n",
    "training_data_noisy = []\n",
    "\n",
    "# Include the non-corrupted data in the dataset?\n",
    "if include_also_non_noisy_simulation:\n",
    "    training_data_noisy.append(training_data)\n",
    "\n",
    "# Append noisy data\n",
    "for snr in snrs:\n",
    "    for int_spike in intensity_spikes:\n",
    "\n",
    "        signal_noisy = training_data.map(add_noise_to_simulation,\n",
    "                                         snr=snr, int_salt=int_spike,\n",
    "                                         inplace=False, parallel=True)\n",
    "\n",
    "        training_data_noisy.append(signal_noisy)\n",
    "\n",
    "del training_data\n",
    "del signal_noisy\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.2s\n",
      "<ElectronDiffraction2D, title: , dimensions: (16200, 7|515, 515)>\n"
     ]
    }
   ],
   "source": [
    "training_data_noisy = hs.stack(training_data_noisy, axis=0)\n",
    "print(training_data_noisy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrate radially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 13.23126531791953]\n",
      "<ElectronDiffraction1D, title: , dimensions: (16200, 7|256)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/113400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70fd65ad7e0b471d8f6d6cb99f9046fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1805"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_length = detector_pix_size / (wavelength * calibration * 1e10)\n",
    "training_data_noisy.unit = \"k_A^-1\"\n",
    "training_data_noisy.set_experimental_parameters(beam_energy=beam_energy)\n",
    "radial_steps = int(np.ceil((int(detector_size/2) - 1)/2)*2)\n",
    "training_data_1D = training_data_noisy.get_azimuthal_integral1d(npt_rad=radial_steps,\n",
    "                                                          center=([detector_size/2,detector_size/2]),\n",
    "                                                          detector=detector,\n",
    "                                                          detector_dist=camera_length,\n",
    "                                                          map_kwargs={'parallel':True})\n",
    "print(training_data_1D)\n",
    "\n",
    "del training_data_noisy\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalise (and sqrt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 16200, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Sqrt signal (if wanted)\n",
    "if sqrt_signal:\n",
    "    training_data_1D.data = np.sqrt(training_data_1D.data)\n",
    "\n",
    "# Normalise\n",
    "dpmax = training_data_1D.data.max(2)\n",
    "training_data_1D_norm = training_data_1D.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "# Correct any nan value\n",
    "nan_mask = np.isnan(training_data_1D_norm)\n",
    "training_data_1D_norm[nan_mask] = 0\n",
    "\n",
    "print(training_data_1D_norm.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add simulated background\n",
    "\n",
    "Approximate background as a $A*exp^{(-tau \\: q)}$ value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 210600, 256)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_background_to_signal1d_array(normalised_1d_sim_data_array, x_axis,\n",
    "                                     a_val, tau_val, bkg_function='exp_decay'):\n",
    "    \"\"\"\n",
    "    :param normalised_1d_sim_data_array:\n",
    "        The normalised 1d signal array (nav axis should be (points, phases, q))\n",
    "    :param x_axis: array of the actual q values\n",
    "        The A and tau values are optimised for 1/A-1 magnitude\n",
    "    :return: extended signal with new sets of sim data without and with bakgrounds\n",
    "    \"\"\"\n",
    "    def inv_q(x, A, tau):\n",
    "        return A * x**(-tau)\n",
    "\n",
    "    def exp_decay(x, A, tau):\n",
    "        return A * np.exp(- tau * x)\n",
    "\n",
    "    if bkg_function == 'exp_decay':\n",
    "        bkg = exp_decay(x_axis, a_val, tau_val)\n",
    "    elif bkg_function == 'inv_q':\n",
    "        bkg = inv_q(x_axis, a_val, tau_val)\n",
    "\n",
    "    s = normalised_1d_sim_data_array + bkg\n",
    "    return s\n",
    "\n",
    "\n",
    "# Expand datasets by copying and adding bkg\n",
    "training_data_1D_norm_bkg = training_data_1D_norm\n",
    "\n",
    "# Get the x-axis values from which to calculate bkg\n",
    "qs = training_data_1D.axes_manager.signal_axes[0].axis\n",
    "\n",
    "# Add bkg to signal\n",
    "for a in a_vals:\n",
    "    for tau in tau_vals:\n",
    "        bkg_data = add_background_to_signal1d_array(training_data_1D_norm, qs, a, tau)\n",
    "        training_data_1D_norm_bkg = np.hstack((training_data_1D_norm_bkg, bkg_data))\n",
    "\n",
    "training_data_1D_norm_bkg.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop, rebin and renormalise\n",
    "\n",
    "Crop both in terms of q (rebin but no shift) and pixel values (shift but no rebin)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Sauron\\anaconda3\\envs\\pyxem\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 210600, 147)\n",
      "(7, 210600, 147)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_norm_bkg = hs.signals.Signal1D(training_data_1D_norm_bkg)\n",
    "\n",
    "training_data_1D_px = training_data_1D_norm_bkg.deepcopy()\n",
    "\n",
    "# Recreate .hspy object to crop with k units\n",
    "scale = training_data_1D.axes_manager.signal_axes[0].scale\n",
    "offset = training_data_1D.axes_manager.signal_axes[0].offset\n",
    "training_data_1D_norm_bkg.axes_manager.signal_axes[0].scale = scale\n",
    "training_data_1D_norm_bkg.axes_manager.signal_axes[0].offset = offset\n",
    "\n",
    "training_data_1D_q = training_data_1D_norm_bkg.deepcopy()\n",
    "\n",
    "del training_data_1D\n",
    "del bkg_data\n",
    "del training_data_1D_norm\n",
    "del training_data_1D_norm_bkg\n",
    "gc.collect()\n",
    "\n",
    "# In k units:\n",
    "# Crop in k units\n",
    "training_data_1D_q.crop_signal1D(cropping_start_k, cropping_stop_k)\n",
    "# Rebin\n",
    "scale_rebin = training_data_1D_q.data.shape[-1] / cropped_signal_k_points\n",
    "scale_rebin\n",
    "training_data_1D_q = training_data_1D_q.rebin(scale=(1,1,scale_rebin))\n",
    "# Renormalise data\n",
    "dpmax = training_data_1D_q.data.max(-1)\n",
    "training_data_1D_q = training_data_1D_q.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "# In pixel units:\n",
    "# Crop in pixel units\n",
    "training_data_1D_px.crop_signal1D(cropping_start_px, cropping_stop_px)\n",
    "# Renormalise data\n",
    "dpmax = training_data_1D_px.data.max(-1)\n",
    "training_data_1D_px = training_data_1D_px.data/dpmax[:,:,np.newaxis]\n",
    "\n",
    "print(training_data_1D_q.shape)\n",
    "print(training_data_1D_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN requirements: reshape and labelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1474200, 147)\n",
      "(1474200, 147)\n"
     ]
    }
   ],
   "source": [
    "training_data_1D_q = training_data_1D_q.reshape(-1, training_data_1D_q.shape[-1])\n",
    "training_data_1D_px = training_data_1D_px.reshape(-1, training_data_1D_px.shape[-1])\n",
    "\n",
    "print(training_data_1D_q.shape)\n",
    "print(training_data_1D_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(1474200,)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels\n",
    "n_phases = len(phase_dict)\n",
    "labels = np.zeros((n_phases, int(training_data_1D_q.shape[0]/n_phases)))\n",
    "for i in range(n_phases):\n",
    "    labels[i,:] = i\n",
    "\n",
    "training_labels = labels.flatten()\n",
    "training_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1468764, 147) (1468764,)\n",
      "(1468767, 147) (1468767,)\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers and nan values\n",
    "where_nan_q = np.argwhere(np.isnan(training_data_1D_q))\n",
    "where_nan_px = np.argwhere(np.isnan(training_data_1D_px))\n",
    "\n",
    "training_data_1D_q = np.delete(training_data_1D_q, where_nan_q[:,0], axis = 0)\n",
    "training_labels_q = np.delete(training_labels, where_nan_q[:,0], axis = 0)\n",
    "\n",
    "training_data_1D_px = np.delete(training_data_1D_px, where_nan_px[:,0], axis = 0)\n",
    "training_labels_px = np.delete(training_labels, where_nan_px[:,0], axis = 0)\n",
    "\n",
    "print(training_data_1D_q.shape, training_labels_q.shape)\n",
    "print(training_data_1D_px.shape, training_labels_px.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p4mbm_tetragonal', 'gratia_2h', 'gratia_4h', 'gratia_6h', 'pbi2_2h', 'pb', 'bkg_phase']\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "phase_names = list(phase_dict.keys())\n",
    "\n",
    "print(phase_names)\n",
    "print(training_labels[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_q\n",
    "y = training_labels_q\n",
    "\n",
    "np.savez('1D_simulated_data_cal{}_cropK_{}classesInclBkg_{}neuler_domainrand_noisy_bkg'.format(calibration,\n",
    "                                                                              n_phases,\n",
    "                                                                        n_angle_points,),\n",
    "         x=x, y=y, phases=phase_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "store_train_data = TemporaryFile()\n",
    "x = training_data_1D_px\n",
    "y = training_labels_px\n",
    "\n",
    "np.savez('1D_simulated_data_cal{}_cropPX_{}classesInclBkg_{}neuler_domainrand_noisy_bkg'.format(calibration,\n",
    "                                                                              n_phases,\n",
    "                                                                        n_angle_points,),\n",
    "         x=x, y=y, phases=phase_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "3705"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.figure()\n",
    "plt.plot(training_data_1D_px[i], label='px')\n",
    "plt.plot(training_data_1D_q[i], label='q')\n",
    "plt.legend()\n",
    "\n",
    "del training_data_1D_px\n",
    "del training_data_1D_q\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}